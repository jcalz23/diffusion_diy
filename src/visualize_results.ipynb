{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "from train_ddpm import UNet_Tranformer, marginal_prob_std, diffusion_coeff\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Euler_Maruyama_sampler(score_model,\n",
    "              marginal_prob_std,\n",
    "              diffusion_coeff,\n",
    "              num_steps,\n",
    "              batch_size=64,\n",
    "              x_shape=(1, 28, 28),\n",
    "              device='cuda',\n",
    "              eps=1e-3, y=None):\n",
    "    \"\"\"Generate samples from score-based models with the Euler-Maruyama solver.\n",
    "\n",
    "    Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps.\n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "\n",
    "    Returns:\n",
    "    Samples.\n",
    "    \"\"\"\n",
    "    t = torch.ones(batch_size, device=device)\n",
    "    init_x = torch.randn(batch_size, *x_shape, device=device) \\\n",
    "    * marginal_prob_std(t)[:, None, None, None]\n",
    "    time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "    step_size = time_steps[0] - time_steps[1]\n",
    "    x = init_x\n",
    "    with torch.no_grad():\n",
    "        for time_step in tqdm(time_steps):\n",
    "            batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "            g = diffusion_coeff(batch_time_step)\n",
    "            mean_x = x + (g**2)[:, None, None, None] * score_model(x, batch_time_step, y=y) * step_size\n",
    "            x = mean_x + torch.sqrt(step_size) * g[:, None, None, None] * torch.randn_like(x)\n",
    "    # Do not include any noise in the last sampling step.\n",
    "    return mean_x\n",
    "\n",
    "sigma =  25.0#@param {'type':'number'}\n",
    "\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)\n",
    "\n",
    "# Load the pre-trained checkpoint from disk.\n",
    "device = 'cuda' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "ckpt = torch.load('ckpt_transformer.pth', map_location=device)\n",
    "score_model = torch.nn.DataParallel(UNet_Tranformer(marginal_prob_std=marginal_prob_std_fn))\n",
    "score_model = score_model.to(device)\n",
    "score_model.load_state_dict(ckpt)\n",
    "score_model.eval()\n",
    "\n",
    "# Set params\n",
    "sample_batch_size = 16 #@param {'type':'integer'}\n",
    "num_steps = 250 #@param {'type':'integer'}\n",
    "sampler = Euler_Maruyama_sampler #@param ['Euler_Maruyama_sampler', 'pc_sampler', 'ode_sampler'] {'type': 'raw'}\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "for i, digit in enumerate(range(10)):\n",
    "    samples = sampler(score_model,\n",
    "            marginal_prob_std_fn,\n",
    "            diffusion_coeff_fn,\n",
    "            num_steps,\n",
    "            sample_batch_size,\n",
    "            device=device,\n",
    "            y=digit*torch.ones(sample_batch_size, dtype=torch.long))\n",
    "\n",
    "    ## Sample visualization.\n",
    "    samples = samples.clamp(0.0, 1.0)\n",
    "    sample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\n",
    "\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.title(f\"Digit: {digit}\")\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_grid.permute(1, 2, 0).cpu(), vmin=0., vmax=1.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
